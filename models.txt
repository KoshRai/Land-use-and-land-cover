#14M params
def double_conv(in_channels, out_channels):
    return nn.Sequential(
        nn.BatchNorm2d(num_features=in_channels),
        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1),
        nn.ReLU()
    )
def double_trans_conv(in_channels, out_channels):
    return nn.Sequential(
        nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1),
        nn.ReLU(),
        nn.ConvTranspose2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1),
        nn.ReLU()
    )

class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)
        self.max_unpool = nn.MaxUnpool2d(kernel_size=2, stride=2)
        self.conv1 = double_conv(3, 16)
        self.conv2 = double_conv(16, 32)
        self.conv3 = double_conv(32, 64)
        self.conv4 = double_conv(64, 128)
        self.conv5 = double_conv(128, 256)
        self.conv6 = double_conv(256, 512)
        self.conv_1x1_1 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=1, stride=1)
        self.conv_1x1_2 = nn.Conv2d(in_channels=1024, out_channels=2048, kernel_size=1, stride=1)
        self.conv_1x1_3 = nn.Conv2d(in_channels=2048, out_channels=1024, kernel_size=1, stride=1)
        self.conv_1x1_4 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1)
        self.conv_1x1_out = nn.Conv2d(in_channels=16, out_channels=5, kernel_size=1, stride=1)
        self.trans_conv1 = double_trans_conv(1024, 256)
        self.trans_conv2 = double_trans_conv(512, 256)
        self.trans_conv3 = double_trans_conv(256, 64)
        self.trans_conv4 = double_trans_conv(128, 32)
        self.trans_conv5 = double_trans_conv(64, 32)
        self.trans_conv6 = double_trans_conv(32, 16)
        self.bn1 = nn.BatchNorm2d(512)
        self.bn2 = nn.BatchNorm2d(256)
        self.bn3 = nn.BatchNorm2d(64)
        self.bn4 = nn.BatchNorm2d(32)
        self.softmax = nn.Softmax(dim=1)
    def forward(self, inp):
        c1 = self.conv1(inp)
        c2 = self.conv2(c1)
        p1, i1 = self.max_pool(c2)
        c3 = self.conv3(p1)
        p2, i2 = self.max_pool(c3)
        c4 = self.conv4(p2)
        c5 = self.conv5(c4)
        p3, i3 = self.max_pool(c5)
        c6 = self.conv6(p3)
        p4, i4 = self.max_pool(c6)
        e1 = self.conv_1x1_1(p4)
        e2 = self.conv_1x1_2(e1)
        e3 = self.conv_1x1_3(e2)
        q4 = self.conv_1x1_4(e3)
        q4 = self.bn1(q4)
        d6 = self.max_unpool(q4, i4, output_size = c6.size())
        d6 = torch.cat((c6, d6), dim=1)
        q3 = self.trans_conv1(d6)
        q3 = self.bn2(q3)
        d5 = self.max_unpool(q3, i3, output_size = c5.size())
        d5 = torch.cat((c5, d5), dim=1)
        d4 = self.trans_conv2(d5)
        q2 = self.trans_conv3(d4)
        q2 = self.bn3(q2)
        d3 = self.max_unpool(q2, i2, output_size = c3.size())
        d3 = torch.cat((c3, d3), dim=1)
        q1 = self.trans_conv4(d3)
        q1 = self.bn4(q1)
        d2 = self.max_unpool(q1, i1, output_size = c2.size())
        d2 = torch.cat((c2, d2), dim=1)
        d1 = self.trans_conv5(d2)
        d0 = self.trans_conv6(d1)
        l = self.conv_1x1_out(d0)
        return self.softmax(l)
        
#28M params
def double_conv(in_channels, out_channels):
    conv = nn.Sequential(
        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1),
        nn.ReLU()
    )
    return conv

def double_Tconv(in_channels, out_channels):
    Tconv = nn.Sequential(
        nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1),
        nn.ReLU(),
        nn.ConvTranspose2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1),
        nn.ReLU()
    )
    return Tconv

class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)
        self.max_unpool = nn.MaxUnpool2d(kernel_size=2, stride=2)
        self.conv1 = double_conv(3, 64)
        self.conv2 = double_conv(64, 128)
        self.conv3 = double_conv(128, 256)
        self.conv4 = double_conv(256, 512)
        self.conv5 = double_conv(512, 1024)
        self.Tconv5 = double_Tconv(1024, 512)
        self.Tconv4 = double_Tconv(1024, 256)
        self.Tconv3 = double_Tconv(512, 128)
        self.Tconv2 = double_Tconv(256, 64)
        self.Tconv1 = double_Tconv(128, 5)
        self.bn1 = nn.BatchNorm2d(64)
        self.bn2 = nn.BatchNorm2d(128)
        self.bn3 = nn.BatchNorm2d(256)
        self.bn4 = nn.BatchNorm2d(512)
        self.bn4u = nn.BatchNorm2d(512)
        self.bn3u = nn.BatchNorm2d(256)
        self.bn2u = nn.BatchNorm2d(128)
        self.bn1u = nn.BatchNorm2d(64)
        self.softmax = nn.Softmax(dim=1)
    
    def forward(self, x):
        c1 = self.conv1(x)
        c1 = self.bn1(c1)
        x1, i1 = self.max_pool(c1)

        c2 = self.conv2(x1)
        c2 = self.bn2(c2)
        x2, i2 = self.max_pool(c2)
        
        c3 = self.conv3(x2)
        c3 = self.bn3(c3)
        x3, i3 = self.max_pool(c3)

        c4 = self.conv4(x3)
        c4 = self.bn4(c4)
        x4, i4 = self.max_pool(c4)
        
        i = self.conv5(x4)
        
        t4 = self.Tconv5(i)
            
        t4 = self.bn4u(t4)
        z4 = torch.cat((self.max_unpool(t4, i4, output_size=c4.size()), c4), dim=1)
        t3 = self.Tconv4(z4)
        
        t3 = self.bn3u(t3)
        z3 = torch.cat((self.max_unpool(t3, i3, output_size=c3.size()), c3), dim=1)
        t2 = self.Tconv3(z3)
        
        t2 = self.bn2u(t2)
        z2 = torch.cat((self.max_unpool(t2, i2, output_size=c2.size()), c2), dim=1)
        t1 = self.Tconv2(z2)
        
        t1 = self.bn1u(t1)
        z1 = torch.cat((self.max_unpool(t1, i1, output_size=c1.size()), c1), dim=1)
#         z1 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=1)(z1)
#         w1 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1)(z1)
        out = self.Tconv1(z1)
        
        return self.softmax(out)